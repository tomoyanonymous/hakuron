# 序文の前に

2021年9月。北九州市の植物園でこのイントロダクションを書いている。

植物園、というか自然公園みたいなこの場所にはフリーランスの仕事で来ている。公園を大きく使ったナイトウォークのようなイルミネーションのようなイベントで、そのための音楽やSEを流すためのシステムを作る仕事である。仕事の半分くらいはスピーカーをどこに配置するかとか、どの機材を使うかとかそういう話なのだが、もう半分はその沢山あるスピーカーにどう音を割り振ったり、パソコンを起動したら自動的に音が鳴り始めるようにするためのプログラムを作る作業になる。

制御のためのソフトウェアはCycling'74社のMaxという音声処理が得意なマルチメディアプログラミング環境で構築している。長い歴史を持ち、現在音楽のためのプログラミング環境としては（知る限り）最も多く使われており、個人的には2015年から使い始めたこのMaxというソフトウェアを使うと、たとえば展示空間にスピーカーを10個とか（それも、いわゆるサラウンドとかとは全然違うレイアウトで）配置してそれぞれに違う音を同期して流したりできる。あるいは、映像を生成するコンピュータからネットワーク経由で特定の信号を受け取ったら特定の効果音を流すようにしたり。

なんだか言葉にすると大したことがない仕事のように聞こえる。実際、プログラムを書く作業自体は主観的には大したことがないのだ（ソフトウェア特有のニッチな問題やらバグは細々あるにしても）。こんな作業でお金をもらってしまっていいんだろうかと思う時もある。

しかし実際のところ似たような仕事ができる人はそこまで多いわけでもないらしい。たとえば、仕事を受けようとしたが予定が埋まっているときに別の似たような職能を持った人を紹介しようと思っても、パッと思いつく人はそう多くない。

これは、自分がこうした仕事に慣れすぎてしまったのだろうか。おそらく半分はそうなのだろう。だがこの仕事をしているとやはり考えざるを得ない疑問は、コンピューターはなんでもできる装置のはずなのに、たかだか沢山のスピーカーに同時にたくさん音楽を流すぐらいのことに、どうしていちいちこんな専用の（しかも有料の）ソフトウェアを使ってカスタムツールを使ってプログラムを作るような手間がかかる作業になってしまうのだろう、ということなのだ。

これは別に、使うスピーカーが多いから必要なコンピューター処理能力が大きい、という話でもない。たとえば、映像インスタレーション作品でどうしてもフォーマット的に3chのスピーカーを制御したい、となったときにも、大体10chの時と同じくらいの面倒臭さが発生する。2chが3chになったりするだけで、普通の音楽制作ソフトウェアでは扱いづらくなる。なんでmacOSでファイルを選択してスペースバーを押したら音声ファイルが再生されるように、物理的なセンサーに触ったら音声ファイルを再生する程度のことに労力が必要なのか。なんでエクセルファイルをちょっと編集するぐらいの手間で10chのスピーカーに音声ファイルを割り振れるようにならないのか。

この疑問こそが、おそらくはインフラストラクチャやフォーマットの持つ力というものの説明なのだろう。つまり、人々は2chのステレオ音声のフォーマットがすでにあるから2chステレオで音楽を作る。作るためのツールも2chが一番主流なのでそれが最も作りやすいように良心的な配慮をしてしまう。それに、いかに音楽や芸術表現が新しさを欲するものだとしても、とりあえずはその2chのフォーマットの中で表現が可能な新しさであれば問題にはならない。そして、別に3ch以上の音声フォーマットも表現として*不可能なわけではない*。ただ、ちょっと手間がかかるのだ。

マルクス主義者風の言い方をすればインフラストラクチャ:下部構造が上部構造—、つまり音楽表現とかを規定するということになるのだろうか。おそらくはそうではない。インフラストラクチャは表現を完全に縛りはしないが**誘導**する。そしてその誘導方向は既存の上部構造によって作り出されるものであり、互いに循環し合いながら徐々に路面は踏み固められていく。

---

こうした実感を持つようになってきたのは自分で音楽のためのプログラミング言語を作り始めようと構想しはじめた2018年の後半ごろからだった。2018年の9月から11月にかけて、筆者はSchool for Poetic Computation（SFPC）という、ニューヨークにあるアーティスト・ラン・スクールへ留学した。SFPCはテクノロジーと表現を批評的に、かつ実践的に学ぶ私学校に近い場である。年に2回、20人ほどの学生（10代から50代まで）が集まり、OpenFrameworks[^openframeworks]を用いたグラフィックプログラミングから技術批評の文献購読までを3ヶ月間、対話を交わしながら進めていく。

[^openframeworks]: C++言語を用いた映像やマルチメディア表現のためのフレームワーク。SFPCを立ち上げたザッカリー・リーバーマンを含むコミュニティによって開発、メンテナンスされている。 https://openframeworks.cc/ 2022年1月24日最終閲覧。

筆者はそれまで、物理モデリング楽器を物理的な要素で再構築するインスタレーション作品の制作や、オーディオフィードバックを主要素とする電子音響楽器の開発とそれを用いた即興演奏などを中心に活動してきた。

これらの作品制作への大元のモチベーションも詰まるところ、先述したどれだけ工夫したプログラムを作ったところで全ては2chのステレオPCMサウンドというフォーマットに収束してしまうことへの窮屈さから来る、より異なる音楽表現の可能性の追求であった。つまりインスタレーション作品も、オーディオフィードバックを用いる電子楽器も、コンピューターにスピーカーを繋げるだけでは実現不可能な表現領域を探索することに意義を見いだしていた。

しかし同時に、音楽のフォーマット（あるいはより広範な意味合いでの形式）から離れたところで、インスタレーションや展示、あるいは即興演奏のイディオムという異なる形式へと従属する対象が変わっただけのようにも感じていた。そうした疑問を抱えながら過ごしたSFPCでの授業は全くこれまでと違う考え方を自分に与えてくれた場所であった。

SFPCの入居しているウエストベス・アーティスツ・コミュニティという建物は、元々1890年代から1960年代までベル研究所の建物だった場所で、有名なところではショックレーらによる世界で初めてのトランジスタが発明された場所でもある。そして同時にこの場所はニューヨークのテクノロジー・アートの歴史の中心地と言ってもよい歴史的な経緯を持つ場所でもある。

ベル研究所のエンジニア、ビリー・クルーヴァーは美術家のロバート・ラウシェンバーグとともに、1960年代にExperiments in Arts And Technology(E.A.T)というアーティストとエンジニアの共同作業のための集団を組織し、『九つの夕べ』のようなイベントを開催したり、1970年の大阪万博ペプシ館の演出を担当するなど、のちのテクノロジーを用いた芸術制作へと大きな影響を与えている。こうしたニューヨークにおける技術者と芸術家の共同作業は、ラウシェンバーグを始め、ウエストベスへのちに入居したダンサーのマース・カニングハムや、彼らとの共同作業も行った作曲家のジョン・ケージやデイヴィッド・チューダーといったアーティストの参加したブラックマウンテン・カレッジや、またケージの参加したフルクサスのような反制度/反形式的な思想や運動を背景としていることが特徴である。これはたとえば人類学者のジョージナ・ボーンが『Rationalizing Culture』（『文化を合理化する』）で、フランスの電子音楽研究所において1970〜1980年代にピエール・ブーレーズのような作曲家が電子音楽のための技術を、現代音楽という積み重ねられてきた歴史の上で正当化する過程を描いた様子とは大きく異なる[@Born1995]。

SFPCのプログラムはこうした歴史的背景をもとに、ブラックマウンテン・カレッジのような既存の教育の枠を外し、生徒が互いに教え合う機会を多く設けた「Horizontal Pedagogy」[^horizontal]と呼ぶ学びの姿勢を重視したものである。またなおかつ、大阪万博を1つのピークとして捉えられる、1960年代のテクノロジーアートにおける、表現に先行して技術を無批判に用いることや、大規模化するごとに資本主義へ迎合していってしまう傾向[^mediaarthistory]への内省も踏まえたものとなっている。技術を用いる際に暗黙的に発生する政治性に自覚的になり、技術を与えられたブラックボックスとせず、すでにライブラリやツールが存在しているものだったとしても一度自分の手で作り直すことによって体でその内容を理解することで、異なる技術のエコシステムの可能性を想像できるようになるというわけである。

[^horizontal]: http://taeyoonchoi.com/2012/05/notes-on-critical-pedagogy/ 2022年1月24日最終閲覧。

[^mediaarthistory]: たとえば、[@Ma2014,58p]の坂根厳夫の引用では、70年代はじめのオイルショックや環境問題を単に発した科学技術自体への批判との共鳴が指摘されているし、大阪万博ペプシ館でのスポンサーによる会期中のプログラム中断と、E.A.Tのその後の活動の衰退をあげることができるだろう。

それゆえ、SFPCで教える講師達の活動形態も、必ずしも作品を作って美術館に展示することが中心なわけではない。OpenFrameworksでほぼ毎日短いCGアニメーションを作り投稿し続けるザッカリー・リーバーマン[^zachaly]や、CPUの動作原理を餃子作りに見立てた『CPU Dumpling』ワークショップを行うチェ[^taeyoon]、ポストコロニアルスタディーズをベースに、白人中心主義的なコンピューター文化批判のインスタレーションやZineを制作するアメリカン・アーティスト[^aartist]、100年以上ただ時を刻むだけのカウンターのようなオーバー・エンジニアリングなツールを自宅の工房で作って自分たちで売り続けるCW&T[^cwandt]……のように、多様な活動を見せる彼/彼女らの活動を通して（それでどうやって生計を立てられるかはともかくとしても）テクノロジーと社会の関係性への向き合い方は必ずしもアートという閉じられた空間の中だけで行うものでなくてもよいのだと実感させられた。

[^zachaly]: http://zach.li/ 2022年1月24日最終閲覧。
[^taeyoon]: https://taeyoonchoi.com/ 2022年1月24日最終閲覧。
[^aartist]: https://americanartist.us/ 2022年1月24日最終閲覧。
[^cwandt]: https://cwandt.com/ 2022年1月24日最終閲覧。


こうした経験が音楽のためのプログラミング言語という実に微妙な領域の制作へ筆者が本格的に入っていくきっかけとなった。

詰まるところ、どれだけ工夫したプログラムを作ったところで全ては2chのステレオPCMサウンドというフォーマットに収束してしまうことへの窮屈さに対して真に向き合うには、何が社会的にそのフォーマットを構築しているのかについて突き詰めて考える必要があったのだ。違う表現の形式へスライドしても結局その形式の束縛を受けるだけになってしまう。ならばやるべきは制作を無意識的に支配している形式や制度そのものの脱構築に他ならない。つまり筆者にとって音楽プログラミング言語の制作とは音楽を生み出す下部構造＝インフラストラクチャになりうる道具自体を自らの手で作ることを通じて、異なる音楽の形式や制度そのものをメタ的に制作する芸術実践でもある。


<!-- 
この大きな問題意識のもと、筆者の音楽プログラミング言語制作の目標はその中で二転三転を経てmimiumという現在のプロジェクトに落ち着く。始めにある程度まとまった人数に対して言語設計の話を持ち出したのは、SFPC滞在期間はじめの自己紹介兼、3ヶ月の間に何をやろうとしているかのプレゼンテーションをする場所だった[^meetthestudent]。そこでは、1つのソースコードに対して複数の処理系を通すことで異なる音楽が発生するという、どちらかといえばCode Poetry[^CodePoetry]などの詩としてのソースコードとその処理系の関係性、コードを書く人と処理系を作る人のオーサーシップの関係性に焦点を当てたものだった。結局SFPCの滞在期間中に制作したのはよりハードウェアのレイヤーでコンピューターの構造と音楽という時間芸術の形式の関係性を問い直すものになり[^edtac]、言語設計を実際に始めるのは日本に戻った2019年からになる。

[^meetthestudent]: SFPC 2018 fall classにおけるMeet the Studentsという公開イベント。YoutubeのURLとSpeakerDeckのスライドを貼る

[^CodePoetry]: プログラミング言語のソースコード自体を詩のように扱う芸術の形式。実際には実行できないがソースコードの見た目を模したもの、実行することで初めて詩として読めるもの、ソースコードとしても可読性があり、実行することでさらにグラフィックを生成するものなど様々な種類がある。[@Montfort2013]などを参照。

[^edtac]: Electronic Delay Time Automatic Calculator(EDTAC)という作品。修士論文[@Matsuura2019mathesis]や2019年JSSA研究会での[@Matsuura2019jssa]を参照。

2019年ごろの設計初期段階では、Mayer、ChughらのSketch-n-Sketch[@Mayer2018]や、JacobsらのPara[@Jacobs2017]、橋本麦によるGlisp(NiU)[^Glisp]など、グラフィック生成のためのアプリケーションにおいて、ソースコードの編集と直接操作(いわゆるDirect Manipulation：Adobe IllustlatorやMicrosoft PowerPointにおけるベクター図形編集のような、図形の要素をGUIで直接サイズ調整できるような種類のアプリケーション)を組み合わせたり、相互に行き来できるソフトウェアを、音楽プログラミングの領域においても実現できないかというアイデアが中心に置かれていた。

[^Glisp]: https://glisp.app。なお、橋本もSFPCへの滞在経験があるほか、Jacobsは筆者の滞在期間中にフィールドワークの一環でSFPCを訪れている。

実際、この提案は2019年情報処理推進機構未踏IT人材発掘・育成事業という、革新的なソフトウェア制作に対する支援事業に採択され、その当初のアイデアはプログラミング言語設計とそのソースコードをグラフィカルに編集できるソフトウェアという2つのプロジェクトを並列して行うものになっていた。[^mitou]

[^mitou]: 未踏IT人材発掘・育成事業：2019年度採択プロジェクト概要（松浦PJ）(https://www.ipa.go.jp/jinzai/mitou/2019/gaiyou_tk-1.html)を参照。また同時期に情報処理学会音声情報処理研究会にて同様の案についてのポスター発表を行っている[@Matsuura2019MUS]。

しかし結果として、2019年6月から2020年2月までの同事業でのディスカッションを中心に実装を進める中で、筆者の興味関心は徐々にその根幹であるプログラミング言語の設計そのものに移ることになった。ひとつの理由は、音声信号は、（考えてみれば当たり前だが）グラフィックにおけるコードと直接操作の相互利用ツールと異なり、**直接操作**など不可能である、ということに気づいたことにある。我々が音楽制作ソフトウェアで波形をマウスで切り貼りしているのは言うなれば音声データのありうる表象のかたちのうちのひとつでしかなくて、空気の振動それ自体ではない。音楽プログラミング言語で表現しようとしているデータ形式そのものも音そのものではない。 -->


# 序文 {#sec:intro}

本研究は音楽土木工学という、未だ存在しない学問領域を、音楽のためのプログラミング言語mimiumの設計と開発を通じて描き出す試みだ。この論文の中で筆者が提起しようとしている音楽土木工学とは、その名前の通り土木工学—つまり街における道路のようなインフラストラクチャ設計や、未来の街の姿自体を検討する都市計画、そのための構造力学や材料工学といった分野を音楽という領域に当てはめて考えてみるというアナロジーに基づくものだ。

では、音楽における**土と木**、インフラストラクチャとはいったいなにか？

例えばわかりやすいのは音楽を流通させるストリーミングサービスだ。まだ音楽の流通がCDや、（違法なものを含め）ファイル単位でのデータ配信が主流だった2005年に、クセックとレオナルドはコンピューターやインターネット技術の発展の先に音楽の姿は「水のような音楽」になると予測した[@Kusek2005]。月単位で水道代を払っていれば、蛇口をひねるだけで水が出るように、特定のサービスと契約していれば、クリックすると好きな音楽がいつでも聴き放題という今日の音楽ストリーム（川）の姿は彼らが予想した未来そのものである。私たちの音楽を聴く生活のあり方は、それを運ぶサービスという名の川が整備されることによって少なからず変化した。これだけでも音楽に関わる工学的研究において、コンテンツにだけ焦点を当てるのでなく、テクノロジーを用いて形成される音楽のインフラストラクチャに目を向けることもまた価値あることだと言えるだろう。仮にその技術そのものに音楽と関連する要素がなくとも、である。

一方で、筆者は音楽土木工学という言葉を、単にSpotifyやApple Musicのような音楽流通サービスを支える技術について考えよう、という意味で提起しようとしているのではない。筆者が意図する音楽における土と木とはむしろ、**音楽のためだけに作られたわけではないが、それでも音楽のあり方に大きく影響を与えているテクノロジーやインフラストラクチャ**のことだ。コンピューターの構造は音楽制作のために設計されてはいないし、インターネットは音楽配信の方法を変えるためだけに生み出されたのではない。しかしそれでもそうした基幹技術は確実に音楽の制作と聴取の変容に影響を与えている。

2022年現在、音楽を聴いたり、演奏したり、作ったりする上で、コンピュータが一切関与しない、という状況はもはや考えづらくなっている。作曲にはProtoolsやCubaseに代表されるDAW（Digital Audio Workstation）ソフトウェアを使用し、配信にはApple MusicやSpotifyのようなストリーミングサービスを通じて、デジタルデータという形で音楽は配布される。最終的に、コンピューターやスマートフォン上のソフトウェアでそのデータをデコードし、DAC（Digital-Analog Converter）によって電気信号へと変換され、その信号はスピーカーへと送られようやく空気の振動になり、私たちの耳へ届く。スピーカーの中にさえデジタル信号処理（DSP：Digital Signal Processing）用のチップが入っていて、なんらかの計算によって音質を調整していることも珍しくはない。2020年以後のCOVID-19が文化に引き起こした影響を考えてみれば、クラシック音楽のコンサートさえも、その場で空気の振動を体感することより、録画録音されたものをコンピューターを通じて摂取することの方が多くなってしまったかもしれない。とかく音楽文化を見れば、マーク・ワイザーの提唱したユビキタス（Ubiquitous：遍在する）・コンピューティング[@Weiser1996]の概念は字義通りには達成されたようにも見える。

それでも、コンピューターという、理論的にはあらゆることが可能なはずの装置を用いて生み出され、届けられる音楽の聴取の主要な形式は、コンピューター以前の録音音楽によって形成されたフォーマット（2chステレオで5〜10分程度の曲）から大きく変化していない。

音楽表現を支えるための道具やインフラストラクチャは、常に進歩的に新しい表現を可能にしてきたよう歴史の中で物語られるものの、実際のところその研究や道具は何を理想としていて、誰がどう方向付け形作ってきたものなのだろう。そして、それは音楽家自身によっても変化を促せるような対象なのだろうか？

こうした問題意識のもと本研究が提示する音楽土木工学は、既存の工学的研究を音楽に応用した分野と比較したときに、対象とする技術的要素の違いという点で特徴付けられる学問である。音楽土木工学はテクノロジーを音楽に応用するのではなく、**音楽の形式の規定に大きく関わるが、必ずしも音楽のために作られたわけではない汎用的なテクノロジー**を、改めて音楽という視点から作り直すことを主眼に置く。

音楽のための工学的研究は、例えば録音技術の研究や音楽/音響心理学のような、必ずしもコンピューターを必要としない研究領域も当然大小存在している。とはいえ、特に現代では先述したユビキタス・コンピューティング的状況を考えれば、音楽のための道具やインフラストラクチャを作る研究としてもコンピューターはその中心的要素となる。

この中でコンピューターを用いるような—つまり情報技術を音楽に**応用する**という、音楽土木工学と対照的な立場として挙げられる代表的研究領域が、いわゆる音楽情報検索（Music Information Retrieval：MIR）と呼ばれる分野だ。MIRという研究分野ではコンピューターという装置を用いて、音楽に関わるあらゆる種類のデータを表現することが試みられる。 例えば、2chの音声信号から録音時の個別の楽器の音声信号を抽出するような音源分離技術、テキストデータから喋り声の音声データを生成するText-To-Speech（TTS）のようなものだ。より音楽に関わるものでは音楽/音声信号に含まれているリズム、ピッチ、メロディ、さらには音色や曲調のような抽象的なパラメーターを統計的手法を用いて抽出したり、逆にそうしたパラメーターをもとに音声情報を変換、合成する研究のようなものがある。これは言い換えれば人間の耳のような生理的器官の機能や、脳の認知的機能をモデル化することが念頭に置かれた手法である。それゆえ、近年の機械学習/人工知能技術の発展とも相まって、音声や音楽に関わるコンピューティング技術の中でもその存在感をますます大きくしている。

一方で音楽土木工学が対象とする技術的要素は、例えばコンピューターアーキテクチャやオペレーティング・システム、プログラミング言語（の設計とその処理系開発）、プロトコルやデータフォーマットといったものだ。こうした技術はコンピューターの技術における抽象化のピラミッドにおいて比較的下層に位置するため、とくに日本では低レイヤー技術と呼ばれることもある。

実際こうした基幹的：テクノロジーにおける土と木に相当する要素を、（音楽のような）ある特定の領域のために再考するアプローチは、近年ではさほど特殊な考え方でもなくなってきている。その要因として、コンピューターの中で用いられる技術を段階的に抽象化し、各レイヤーにおける技術的最適化を試み、下層の技術はその上で何を表現するかを考慮しなくても良いという、これまで主流だった考え方が通用しなくなってきたことがある。

例えば画像データの処理や機械学習のような、並行して同時に計算可能なタスクはコンピューターアーキテクチャ、つまりCPUや記憶装置など、コンピューターを構成するハードウェア群自体の設計を並行処理に適したユニット（GPUなど）を利用することで処理速度を大幅に向上させられる。この性能向上の程度は今日、上層のソフトウェアのアルゴリズムだけで改善できる程度を大きく上回っている。

コンピューター科学の分野ではこれまで、ムーアの法則と呼ばれる、ICチップにおけるトランジスタの集積率が年々指数関数的に増加することが見込まれてきた。しかしこの傾向が今後頭打ちになることが見込まれてきたことなどを理由として[^denard]、近年ではドメイン固有アーキテクチャ（Domain Specific Architecture：DSA）と呼ばれる、特定の処理のために専用のプロセッサを計算機に実装することの必要性が提起されている[@Hennesy2019]。DSAの代表的な例としてはGoogleによる機械学習に特化した演算ユニットであるTPU（Tensor Processing Unit）が挙げられる[@Jouppi2017]。

[^denard]: 実際、デナード則という、集積率を上げて処理性能が向上しても電力消費は一定のままであるという法則は2006年ごろから崩れているという見解がなされている[@Hennesy2019]。

こうした処理性能の話に限らずとも、例えばArduinoに代表される、専門家よりも趣味やアーティストらの作品制作を対象にした、マイクロコントローラー[^micon]を用いる電子工作のためのツールキットもまた局所最適ではなく広いレイヤーをまとめ上げることで新たなコンピューティングシステムの価値を提示した例である。ArduinoはAVRマイコンというすでに存在している技術的要素と、必要最低限な入出力の規格化、ハードウェア設計のオープンソース化、初心者にも親しみやすい開発環境ソフトウェア（IDE）という、各種レイヤーにすでに存在していた技術をパッケージにすることで多くの非専門家に電子工作の門戸を開いてきた。

同様に、プログラマブルではあるが、ある程度特定の目的に特化したミニコンピューターという系列で、Belaのような音楽に特化したハードウェアも挙げられる[@McPherson2017]。Belaは、BeagleBone Blackという、Linux（オープンソースのオペレーティングシステム）を搭載する既存のオープンソースミニコンピューターのための、音声入出力インターフェースを備えた拡張ボードだ。その特徴は単にハードウェアだけがプロダクトに含まれているのではなく、USBケーブルで自分のラップトップなどと接続すると、Arduinoと似たような形で、そのラップトップのWebブラウザ上から簡単にプログラムを書き換えられるような開発環境がセットになっている点である。さらに、音声信号処理において特有の問題である入力データが出力に反映されるまでの遅延を極力取り除くために、オペレーティングシステムの機関部分（カーネル）にXenomaiと呼ばれる拡張が加えられていることも特徴のひとつだ。このハードウェアとカスタムOSの合わせ技を利用することでBelaは、より高速なCPUを積んだラップトップやデスクトップコンピューターでも実現できないような低遅延のシステムを構築できる。

[^micon]: AVRやPICに代表される、OSなどを用いない小規模の計算機の総称。マイコンと略される。

このように、これまで利用目的を問わず万能に対応できるよう構築されていたハードウェアとOSのような基幹的な技術要素を、（音楽のような）特定の目的のために作り直してみたり、開発環境ソフトウェアのような高レイヤー技術も含む複合的な組み合わせを検討することで、特定の課題が解決される可能性は大いに増えている。電子回路やハードウェア設計、実装自体の個人レベルでの取り組みのハードルが下がってきたこともこれらの傾向を後押ししている。

# 研究領域のデザイン

<!-- 2章の内容 -->

このように本研究で提起しようとしている音楽土木工学は、音楽に関わる工学の異なる関わり方の追求ではある。一方で筆者はその理論的な基盤を工学や科学よりもデザイン学においている。

デザインというとグラフィックデザインやインテリアデザインのような視覚的表象の操作や、あるいはインターフェースデザインやWeb/アプリケーションのデザインのようなユーザーの認知的特性に基づく使いやすい道具の操作方法の設計、といった分野を想起させる。しかしデザインは歴史の中でその意味を、単に良い製品の創出といった側面だけではなく、社会システムのような抽象的なものを含めた、人工物の創出全般に関する学問という性質を備えてきた。

デザイン学は1960年代以降、サイバネティクス、認知科学、記号論、科学技術社会論（Science, Technology and Society：STS）のような様々な学術領域の知見を取り込みながら発展してきた。その中では例えば、クリティカル・デザイン/スペキュラティブ・デザインのような必ずしも実用的に役に立つものを作るだけでなく、人工物を通じた未来の社会像についての議論の誘発を目的とするデザインがある。研究分野としてのデザインとしても、作られた人工物そのものを最終的な知の貢献とするだけでなく、それを作る過程や使われる過程で得られた知見を共有することに主眼をおいたResearch through Design（RtD）のような独自の研究プログラムが立ち上がりつつある。RtD的な研究は、客観的かつ再現可能な証拠のみに依拠するのではなく、研究者やユーザー（あるいは共同参加者）の主観的表現を積極的に用いる、実証主義的な科学と異なる方法論が提起されてきた。

特にヒューマン–コンピューター・インタラクション（HCI）のような、電子計算機と人間の関わり方を探求する学問分野は、音楽のための新しいシステムとインターフェースを研究するNew Interfaces for Musical Expression（NIME）のような新しい研究分野を生み出してきた。しかしこうした研究は、必ずしも典型的な科学のように私たちの世界の仕組みを解明、理解する営みとも言い難い。そのためHCIやNIME研究の理論的基盤を、RtDのようなデザインリサーチの系譜に位置付ける動きが活発になっている。本研究はそうした流れの上で、音楽のためのプログラミング言語の設計と実装の実践的経験と、音楽に関わるテクノロジーやメディアとしてのコンピューターの歴史にまつわる言説の批判的検討を通じて、音楽のテクノロジーの関わり方の異なる現在（Alternative Presents）やありえるかもしれない未来（Speculative Futures）[@Auger2010]を描き出すことを試みる。

本研究のアプローチは、近年のデザインリサーチの方法論の中でも3つの特徴的な点を持っている。まず1つは、アーティストや音楽家のような表現を行う主体自らが、通常所与のものとされているテクノロジーの仕組みを自分で作ってみることで理解する、**技術的なブラックボックスを開くアプローチ**である。この、ブラックボックスを開くという言い回しは特に科学技術社会論において1980年代以降とりわけ用いられてきたものだ。時代とともに高度に積み重ねられ分析することが不可能になっていく科学の知の体系の成立過程を、研究室におけるフィールドワーク（いわゆるラボラトリー研究）や参与観察を通じて明らかにするという意味合いでブラックボックスという表現が用いられてきたのである。

その上で、本研究におけるブラックボックスを開くとはむしろ、観察者というよりも、元々非専門家であるアーティストや音楽家がDIY的に通常とは異なる目的で技術の根幹的部分に分け入っていく、あるいは**自らが技術者になってしまう**ことでその中身を理解するという意味合いで用いている。このアプローチは技術者やデザイナーの視点から見ると、デザインにおける想定されたユーザーのための道具作り、ユーザー中心的デザイン（UCD:User-Centered Design）の批判的継承として位置付けられる。ユーザーフレンドリーな道具というのは、裏を返せばユーザーを受動的消費者にするデザインでもある。通常、既に使える道具として与えられているものを改めて作るという行為は、科学や工学の中では、車輪の再発明や、DRY（Don't Repeat Yourself）の原則のような言葉で避けられることだ。しかし、作られたものが再発明だったとしても、自らの身体を用いて道具の仕組みを理解する過程それ自体は必ずしも無駄なこととは言えない。それだけでなく、既に固定化されてしまったテクノロジーの異なる姿を想像するための手がかりとなることもある。例えば城一裕らによる『車輪の再発明プロジェクト』では、レコードや写植、スピーカーのような単純な仕組みで作動するメディア技術を、デジタルファブリケーションの普及などにより、個人で利用できる技術環境が変容した中で改めて別の形で作り直すものだ。この中では、紙の上にカッティングプロッターで溝を刻んだレコード、写植の文字盤を多光源プロジェクションのスクリーンとして利用する技法、耳を磁石で挟み込みコイルを近づけることで骨伝導を介して音を聴く『超超短距離電信装置』のように異なるメディア環境の可能性を想像させる道具が生み出されている[@Jo2016]。本研究ではこうした取り組みを参照しつつ、元々音楽表現のバックグラウンドを持つ筆者自身が、mimiumというプログラミング言語を実際に作りながら、音楽のためのプログラミング言語とはそもそも一体なんなのかという存在論を提示する。

2つ目の特徴的な点は、デザインを通じて技術やメディアの歴史観の批判的再構築を試みることだ。ミシェル・フーコーの『言葉と物』や『知の考古学』以降の、歴史が絶対的事実の積み重ねではなく、特定の誰かが記述することによって社会的に構築されていくことを前提とした価値観の中では、異なる技術環境を想像することはこれまでと異なる視点で技術とメディアの歴史を見つめ直すことに他ならない。こうした視点の代表的アプローチとして、フータモやパリッカのようなメディア研究者を中心に議論されている**メディア考古学**[@Huhtamo2015;@Parikka2012]と呼ばれる、淘汰されたメディア装置を足がかりに異なる技術の歴史の可能性を示唆する研究群が挙げられる。先述した『車輪の再発明プロジェクト』はメディア考古学とスペキュラティブ・デザインのアプローチとを接続したものでもある。本研究では音楽のためのプログラミング言語という、これまではコンピューター音楽という1つの芸術ジャンルの中の要素として位置付けられてきたものを、コンピューターを使って音を生成する試み全般という広い視点から再度位置付ける。またその中では、後年の研究からは参照されることがなかった、ある種の失敗したプロジェクトの歴史を積極的に掬い上げることでこれまでの歴史観の相対化を試みる。

3つ目の特徴は、非物質的インフラストラクチャへの着目である。ここで言う非物質的インフラストラクチャとは、主にISOやANSI、JISで定義されるような標準規格（Standard）やフォーマット、プロトコルといったものを指す。こうしたインフラストラクチャは、コンピューターというシンボルを取り扱う装置が中心となった文化的環境の中では、レコードや写真のようなメディアのような表現の基底としての役割を果たす。しかしその一方で、非物質的インフラストラクチャは物理的実体を持たないがゆえに、ある種の社会契約に近い性質も持っている。音響メディア研究者のジョナサン・スターンは著作『MP3』で、MP3という非可逆圧縮の音楽ファイルフォーマットの成立過程や受容の過程を細かく調査することで、フォーマットもメディウム同様に表現や文化の成立の条件に大きく関わっていることを明らかにし、メディア論に留まらないフォーマット理論の必要性を指摘した[@Sterne2012]。このようなインフラストラクチャに着目するという行為は、普段は不可視とされているものに着目するという点で、ブラックボックスを開くアプローチとも近しいものだが、さらに2つの視点を与えるものである。ひとつは、社会に大きくインパクトを与えた革新的研究（Innovation）ではなく、すでに社会に浸透してしまったテクノロジー（In Use）に注目するという点。もうひとつは、長い時間を掛けなければ変化させることが難しいことを予め前提にする点である。

<!-- ボウカーの退屈な研究の話 -->

技術を形づくる主体がその内容を深く理解し、また同時にその使われ方への批判的視座を持つということは技術を作る個人の政治性に自覚的になることでもある。テクノロジーが社会の変化に大きな影響を与えうることが当たり前になりつつある現代において、安定したパラダイムの中では中立的立場に見える、パズルを解くだけのような技術研究[^puzzlesolving]はもはや成立しない。だからこそ、誰が誰のために技術を形作るのかという視点でのオルタナティブな工学のかたちを追求する必要がある。

[^puzzlesolving]: パラダイムという言葉を普及させたトーマス・クーンの『科学革命の構造』では、ある安定したパラダイム（特定の科学的領域をささえる認識の共有された構造[@Fukushima2021,p8]）の中での科学的研究（通常科学）はパズルを解くような物と表現される[@Kuhn1971,p30]。

ここに、音楽土木工学という学問の命名理由のもう1つの理由、日本語の土木工学という言葉に相当する領域を指す英単語、**Civil Engineering**という言葉の選択がある。このCivil Enginneringという語は、現在では概ね日本語における土木工学と重なる領域を指してはいるものの、元々はEngineerという語が軍事的な技術に関わる工兵的な意味合いを持っていたのと対比して用いられるようになったものだ[^civil]。

[^civil]: Civil Engineerという語は一般的に、1750年ごろにイギリスの工学者ジョン・スミートンが自らの専門を、相容れない軍事的な研究と区別するために名乗り始めたことが起源とされている[@Florman1988]。

コンピューター自体が軍事的用途のために作られ、戦後も軍事技術の国家予算のもと多くの研究がなされてきたことはもはや言うまでもない。しかし、音楽に関わるコンピューティング技術に関してもそれは例外ではない。Maxを開発したミラー・パケットは、Maxにおけるもっとも基礎的な値を持たないデータである`bang`や、それを処理する`trigger`といった語の由来は文字通り軍事技術に由来するものだろうと述べている[@Puckette2020]。実際、1980年代にはパケットが務めていた電子音楽研究所IRCAでコンピューター音楽のために作られた高性能なワークステーション4Xは、商業化を試みた結果として軍事的なシミュレーションにだけ利用されると言う結果を生んでいる（[@sec:ircamcontradiction]参照）。こうした歴史は、工学の中でも芸術や人文学に関わる分野でさえも、政治的、倫理的立ち位置に中立な研究などあり得ないことを端的に示している。

つまり、音楽土木工学とは音楽とテクノロジーという都市における土と木に相当する要素を考える学問であると同時に、音楽のための市民工学という意味合いを持つ。この両面のアナロジーは、筆者が学んだSchool for Poetic Computationを立ち上げた人物の1人、アーティスト/アクティビストのチェ・テユン（Taeyoon Choi）の『Open Circuit, Open City』という文章からインスパイアされたものだ[@Taeyoon2016]。

チェはSFPCでの授業を始め様々な場所で、ロジックICを組み合わせてシンプルな計算機をDIY的に作る『Handmade Computer』プロジェクト（[@fig:taeyoon]）や、餃子を作る工程を複数人で分担し、その作業分担の方法からコンピューターにおける逐次処理・並列処理の違いを体感的に学ぶ『CPU Dumpling』ワークショップなどを行ってきた。ともするとこれらのプロジェクトは、いわゆるシチズンサイエンスにおける科学実験の体験教室のような、馴染みのない科学的作業を身近にすることを目指したものと似たように映るが、その目標は大きく異なる。かといって、ここで作られた原始的な電子計算機はその機能性や仕組み自体がこれまでの電子計算機に対するオルタナティブなものというわけでもないし、芸術作品として計算機の見た目に美的価値を付加しようとしているのでもない。同文献でチェは次のように述べている。

> コンピューターを手作りすることで、はんだ付けや配線を繰り返す中でたくさんのことを考える時間を得た。コンピューターがどのように進化してきたかを知ることで、歴史に対する理解がより深まった。同時に、何が最近になってようやく可能になったのかを学ぶことで、オルタナティブな過去、そしてそれが照らし出すオルタナティブな現在とオルタナティブな未来という、テクノロジーとの異なる関係性を想像するインスピレーションを得られた。

> 都市はよく、コンピュータと似て、ブラックボックスの中に封じ込められ、暗号化され、抽象化される。都市の住民は、空間がどう作られ使われるかを限られた範囲でしか制御できないし、私的に保有される公共空間もその意味でまたブラックボックスである。基礎的な部品からわたしたち自身のコンピュータをゼロから作ることで、〔自己を〕回復するためのオルタナティブな都市空間の創造を想像できはしないだろうか？

> 都市は、コンピュータと似て、美学的熟考のための中立的対象ではない。そうではなく、競合し合う政治性と、危うくて不安定〔precarious〕な生活とが置かれた場なのだ。[@Taeyoon2016,筆者訳]

![チェ・テユンによるHandmade Computerプロジェクトのひとつ、4 BIT FSM（Finite State Machine）[@Taeyoon2015]。](img/taeyoon_handmade.jpg){#fig:taeyoon width=70%}

チェが行っているのはむしろ、自らが作ったり（DIY）、誰かと一緒に作ったりする（DIWO：Do it with Others）過程で、そもそもテクノロジーとは誰が誰のために形作るものなのかという問いを投げかける行為だ。

こうしたプロジェクトは、スペキュラティブ・デザインのような、テクノロジーのあるべき未来の姿についての議論を巻き起こすことを目的とした人工物のデザインともまた少し態度が異なる。それは、作家自らが科学的技術を実践するか否かという点である。スペキュラティブ・デザインを提唱したダンとレイビーは、デザインと科学の付き合い方を4つに分類し、自らは「*Design about Science*（科学研究から生じる問題や影響について、デザインを通じて考察する）」というアプローチに着目していた。これに対して、チェのようなアプローチに当てはまるのは「*Design through Science*（デザイナーが多少たりとも科学を実践する）」という態度である[^speculate]。デザイナー自身が科学技術の実践者になるという事はすなわち、技術者の身体的感覚に結び付けられており、言語かできる以前の状態に留まっている知識をデザイナー自らが身につけるということを意味する。この時、デザイナーや人類学者が科学技術研究者を観察したり、デザイナーと科学者がコラボレーションするだけでは取り出すことが敵わなかった、新しい伝達可能な知を見つける可能性が立ち上がってくる[^communicable]。

本研究のアプローチは、一般的には音楽や芸術表現と無関係なものと思われている事柄の設計と実装—例えばプログラミング言語やコンピューター自体—に自ら取り組み、その技術を理解することによって初めて得られる視点をデザイナー/アーティストの批評的視点と接続するものだ。そうすることによって、技術者に埋め込まれこれまで共有されてこなかった知を一度取り出し、さらに異なる方向性を見出す、いわば**Research through Design through Science（Technology）**とでも呼ぶべき態度である。

[^speculate]: [@Dunne2015,p208]。この他に「Design for Science（科学研究を伝えたり、わかりやすく説明したりするためにデザインを用いる）」、「Design with Science（デザイナーと科学の真のコラボレーション）」という2つの関わり方が挙げられている。

[^communicable]:Research through Designという言葉が作られるきっかけとなった、クリストファー・フレイリングの『Research in Art and Design』では、アートやデザインの領域における研究行為をinto（歴史研究など、一般に「研究」と認識されているもの）、through（アクションリサーチや材料研究）、for（アーティストやデザイナーが自らの制作のために行う個人的な探求）という3つの接続詞で分類した。このうちforは「伝達可能な知（Communicable Knowledge）」を生み出すことを一義的な目的としておらず、その知は制作者やあるいは作られた人工物に埋め込まれる（Embodied）とされている[@Frayling1993]。詳しくは第2章を参照。

# なぜプログラミング言語なのか

<!-- 3章のメタメディアの内容に対応する -->

では、音楽におけるコンピューターの利用のされ方を再デザインするための試みとして、なぜ**音楽のためのプログラミング言語：Programming Language for Music（PLfM）**[^plfmdef]を作ることが役に立つのだろうか。それは音楽のためのプログラミング言語の構造を知ることがわたしたちの音楽に対する認識—平たく（かつ大仰に）言えば、私たちにとって今日の音楽とは一体なんなのかという疑問を理解することにつながるからだ。

[^plfmdef]: このPLfMの詳しい定義に関しては第4章の冒頭を参照。

音楽のためのプログラミング言語が一般的に多くのアーティストにとっては、使うことならともかく、言語自体の設計や実装に至っては技術的に高度すぎて理解することが困難であることも、ひとつ重要な点ではある。しかし、音楽プログラミング言語に限らずとも大抵の音楽制作ソフトウェアや、その中で使われるプラグイン、あるいは電子楽器などが技術的にどう作られているかはやはりほとんどの場合においてブラックボックスである。こうしたツール群と音楽のためのプログラミング言語とで何が異なるのかといえば、当然、音楽プログラミング言語が言語であることである。

プログラミング言語はコンピューターという機械に対する命令を記述するものなのだから、あたかも自然言語と同列のように扱うのは不自然に思えるかもしれない。しかし、コンピューターに対する命令は最終的に0/1の羅列である機械語として記述されるのだから、もし人間が0/1の羅列だけでコンピューターに対する命令をスラスラと記述できるのであればはじめからプログラミング言語などは必要ない。そういう意味では、人間が理解可能な形で記述されたテキストデータを機械語へと翻訳することで動作するプログラミング言語というシステムは、根本的には徹頭徹尾人間のための道具であり言語である。そして、プログラミング言語とは人間が思考し記述したモデルを計算機上で実際に動作させることができる道具だが、これは裏を返すと、計算機が理論上どんなに万能の装置であったとしても、人間が記述できない概念をコンピュータープログラムとして動作させることは敵わないということになる。

この万能性と言語による制約という矛盾めいた状況は、トール・マグヌッソンがコンピューターを用いた楽器の特徴を**認識論的道具**とあらわしたことに対応する[@Magnusson2009]。

本研究はマグヌッソンの議論を引き継ぎ、音楽のためのプログラミング言語における、音楽のための最小限の抽象化とは一体なんなのかという問いをmimiumという言語の実装を通じて検討する。今日既存の音楽のためのプログラミングシステムや、それらを用いることで実現される様々な音声合成の手法は依然多くが現実世界のメタファー（楽譜や楽器、モジュラーシンセサイザーなど）に依存している。それ自体はマグヌッソンの指摘した原理的限界とも言えるものだが、問題はその具体的メタファーの部分はプログラムの意味論としてはじめから言語に組み込みのものとされており、その内容はC++のような汎用プログラミング言語で記述されることだ。これは実用的な問題として、各プログラミング言語ごとにそれぞれの言語が考える（とはいえ現実的には粒度の粗い）「最小限」が多数存在していることで、言語ごとの相互利用がままならないという問題につながる。

しかしより根本的な問題として挙げられるのが、具体的メタファーに基づいた言語仕様が存在していることで、コンピューターをメディア装置として使う際の随一の特徴である、自らの機能をプログラミングという手段を用いることで変化、拡張させられる**メタメディア**としての機能に限界が生じてしまうことだ。メタメディアの思想の源流であり、今日のGUIを中心としたパーソナルコンピューティングの姿に大きく影響を与えたアラン・ケイとアデル・ゴールドバーグによるDynabookの研究[@Kay1977]では、コンピューターを使う人が自身でプログラムを書くことによって、自らの道具（ソフトウェア）の機能を自らに合わせて拡張させることが思想の根幹に置かれていた。だが、今日プログラミングという行為の裾野は随分広がったとはいえ、音楽を作るためのソフトウェアの機能をプログラミングを用いて自ら拡張できるような環境は、未だメインストリームとは程遠い[^dawprogrammable]。この自己拡張性の少なさは時に、想像できないことはプログラムとして記述のしようがないという限界にとどまらず、実現したいと思っている機能があるにもかかわらず（そして、プログラミングの知識があったとしても）容易に拡張することが難しいという状況を生んでいる。

[^dawprogrammable]: 数少ない例としては、Ableton社のLiveにおける、音楽プログラミング環境Maxを内部拡張として用いることができるMax for Live、独自のスクリプト言語であるReascriptを使用できるReaperなどがある。

つまりプログラミング言語についての理解を深めるということは、特に音楽という分野においては、個々の人間が音楽の認識を形作る仕組みを理解することでもある。そして、同時に音楽を作るための道具が、社会の中で人間の創作や受容にもたらす自由と制約をどう形成するのかを理解することでもある。

<!-- （もうちょっと補足してもいいかも） -->

# 本論文の貢献

<!-- （順番を整理したほうがいいかもしれない） -->

本論文を通じて学術的に貢献する内容は、大きく分けて3つである。

1つは、「音楽のためのプログラミング言語とは何か？」という、PLfMの存在論の提示だ。PLfMは歴史的にコンピューターを用いて音楽を生成するための技術としてスタートしつつも汎用プログラミング言語の理論を取り込んで発展してきたことにより、一重に音楽のためのプログラミング言語/環境といってもその応用範囲や想定される使用方法、さらに内部の実装方法までが多岐に及び、単純な比較をすることが難しい。また、評価のための語彙も「表現力が高い」「効率的」「汎用的」などの言葉が共通認識の無いまま慣例的に使われており、実際に何を意味するかもはっきりしないことがある。本稿ではまず音楽プログラミング言語の歴史的変遷を改めて整理した上で、「PLfMにはどんな種類があるのか」、「PLfMの特性はどう記述できるか」といった概念を整理して提示する。

2つ目は、「音楽のためのプログラミング言語を音楽を設計するという行為とは何か？」という問いである。録音技術（音響再生産技術）に端を欲した音楽のフォーマットは現在空間音響技術のためのフォーマットの普及などよって、原音再現という従来の明確な1つの目標を失いつつあるだけでなく、新しさを謳いながらも一方でインフラストラクチャの性質による音楽の形式を画一化する傾向を持っている。その環境でコンピュータ上の表現の自由度を最大限担保するためには、プログラミング言語そのものを音楽のためのフォーマットとして再考する必要がある。こうした背景から、本研究ではPLfMの設計行為を2020年代以降におけるテクノロジーを主体的に使う音楽実践の1つのあり方に位置付けることを試みる。さらにこれは、デザイン学におけるデザイン実践を通した研究の領域の広がる中で、社会構造自体を長い時間をかけて変化させていくことを試みる動きとも呼応する。これまでデザインリサーチ的手法は HCIの研究法の1つとして狭い意味ではPLfM研究にも適用されてきたが、本研究ではプログラミング言語設計という行為をさらに一般化し、音楽土木工学という、誰もがアクセス可能な音楽のためのテクノロジーの変革のための政治的行動という広い領域へ接続する。

3つ目は、筆者が設計/実装した自己拡張性の高い音楽プログラミング言語『mimium』についての設計思想とその具体的な実装を提示した上で、以上2つの観点からの位置付けを試みることだ。mimiumは先述した音楽のためのプログラミング言語の歴史を見直し、汎用プログラミング言語の設計の上に最低限の音楽のために特化した言語機能を備える構造を取ることで音楽のための言語におけるブラックボックスを減らしながらもその実装の単純さと自己拡張性の高さを同時に実現できるように設計されている。


# 構成

![本論文全体の構成。](img/thesis_structure.pdf){#fig:structure width=100%}


第2章以降は以下のような構成で論じる。本論文全体の構造を[@fig:structure]に示した。全体としては、2〜4章で1960年代から2020年までの歴史をデザインリサーチ、メディアとしてのコンピューター、音楽のためのプログラミング言語というそれぞれの視点から振り返る。これらの歴史は例えばデザインリサーチとデザインであれば1970年代以降のコンピューターを用いた機器のインタラクションデザインという点で重なりはするものの、概ね独立して読めるような構成になっている。第5章は通時的な視点でのPLfMの整理、第6章は実際の言語設計と実装についての解説、第7章はその実装の問題点を起点にした省察である。なお、第2章から4章にかけての歴史的文脈の整理は、必ずしもmimiumという言語制作の背景として事前に定まっていたわけではないことに注意する必要がある。第2章で詳しく説明するように、本研究の特徴的な点は実践を通じたこれまでとは異なる視点での歴史記述にあるからだ。本研究全体は歴史の批判的考察と、mimiumの設計と実装を相互に繰り返しながら互いにその結果をフィードバックし合うことで成立している。その意味で、第2章から第4章は研究背景であると同時にリサーチのアウトプットでもある。

第2章では、まず音楽のためにコンピューティング技術の基礎的要素を再考するという筆者の研究の立脚点をデザインの歴史から説明する。コンピューター上で動作するシステムやインターフェースを作るということは、何か特定の課題が存在し、それを解決するための道具を作り、その効果を測定するといった工学的な視点で捉えられ実施されてきた。しかしその歴史には並行してコンピューター以前に始まっていた工業製品のデザインにおける科学的手法と、その合理化に伴う功利主義やデザイナーの主体性の欠如への批判といった文脈も存在している。こうした批判的態度から立ち上がってきたクリティカル・デザイン、スペキュラティブ・デザインや、科学と異なる研究プログラムとしてのデザインの議論はHCIやNIME研究の中でも徐々に受け入れられてきている。本研究ではその文脈にさらに、デザイン実践を通じて歴史認識を再構築する研究アプローチという視点を、筆者のこれまでの活動も踏まえて導入する。

<!--3と4もう少し現在の内容に合わせて修正したい -->

第3章では、メタメディア装置としてのコンピューターの思想の当初の理想とその現状について、エマーソンの『Reading Writing Interfaces』[@Emerson2014]を参照しつつ、ユーザーが真っ当にソフトウェアを作ることで音楽表現を行うことは難しく、テクノロジーを積極的に用いる芸術家のアプローチをベンディング（≒技術の誤用）的アプローチへと近づけたことを示す。その上で、2000年代までは機能していたサーキットベンディングやグリッチのようなアマチュアリズムを伴う意図的な技術の誤用は今日のソフトウェア中心の音楽技術文化の中ではもはや機能せず、技術を深く理解した上で、コンピューターというブラックボックスを自らの手で開いていくようなアプローチへと転換を迫られている。これは2章で議論するデザインの運動とも並列しており、そのブラックボックスの開き方の具体例を音楽に限らないデザイナーやアーティストの取り組みから比較することで、ブラックボックス性の少ない、インフラストラクチャとしてのPLfMの設計を広義の音楽実践として位置付けることを試みる。

第4章ではより具体的な例を挙げつつ、PLfMの歴史を整理し、現在設計すべき言語の方針についての示唆を得ることを目指す。ここでは既存のコンピューター音楽のためのプログラミング環境についての文献を参照しつつも、これまで参照されることの少なかった（≒失敗した）試みにも光を当てる。この章ではジョージナ・ボーンのIRCAMにおけるフィールドワーク[@Born1995]や、田中によるチップチューンの歴史の研究[@Tanaka2017]も参照しつつ、コンピューターを用いて音を生成する実践が、産業や大学/研究所のような制度化された場との関係性の中でどのようにインフラストラクチャを形成してきたかに着目する。今日、音楽家がコンピューターを用いて音楽を作る上でプログラミングという手段は主要なものでないが、コンピューターを用いて音を生成する試みがはじめからそのように明確な分業化がなされていたとも考え難い。ではプログラミングはいったいいつから音楽家にとって高度でハードルの高いものになったのか、ということを歴史的起源を辿ることで明確化する。

第5章ではPLfMの現代における特性や概念を通時的な視点で整理する。そのために、PLfMの実装の方法の違いをドメイン固有言語のデザインパターン、汎用プログラミング言語における評価語彙の研究を参照しつつ、PLfMを使用するプロセスをHuman-in-the-Loopモデルとして提示する。ここでは中間表現の粒度（ランタイムのブラックボックス）を大きくすれば動的変更に強くなる、小さくすれば表現自体の汎用性が高まる、動的変更と汎用性を両立しようとすると設計が複雑化し実装のコストが嵩むといった根本的トレードオフが存在することを提示する。

第6章では筆者が設計した音楽のためのプログラミング言語mimium[@Matsuura2021]の詳細を記述する。mimiumは型推論を伴う静的型付け言語であり、汎用の関数型プログラミング言語の設計や実装に、音楽のための言語仕様を2つ、最小限追加する形で実装されていることが大きな特徴である。1つは関数の実行のスケジューリングを行う`@`演算子、もう1つは内部状態を伴う信号処理を通常の関数と同じように記述可能な、状態付き関数の記法である。mimiumはこの2種類の記法を持つことで、これまではブラックボックスとして与えられていた基本的処理の単位をライブラリとして(実行性能を損なわないまま)実装可能であることを、既存の言語との比較を交えて示す。

第7章では、mimiumの実装過程を踏まえて全体の議論を総括し、音楽土木工学という学問の必要性を改めて提示する。これまで作曲、楽器制作のような各表現のレイヤーごとに個別に言語が作られてきた状況（Multi-Languageパラダイム）は、mimiumを含むモダンな言語によってよりメタメディア的状況へと近づきつつはある。しかし、依然としてそうした言語自体の設計や実装には、音楽とは異なる知識やスキルセットを必要とし、異なる形の分業を生み出している。音楽家が自らの道具を自らの手で作れるような環境づくりには、理想的なツールや言語が存在するだけで十分とは言えず、道具やインフラストラクチャを作る事自体の価値判断の変容を促すメタ的な行動が求められる。技術者や音楽家といった役割分担を知らず知らずのうちに前提としてしまっている私たちの文化から一度離れて別の場所へ向かうための暫定的な運動として、音楽土木工学というこれまでとは異なる考え方の学問領域が提唱されるのである。