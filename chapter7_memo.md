
例えば、Pucketteはサンプリング理論に対する不満、と名付けた論考の中で、連続領域で（例えば微分方程式などの形で）構築した楽器や電気回路の数学的モデルを離散化してから計算するような例を挙げ、すべての表現がサンプリング理論に基づく、各時刻における音圧に対応した数値を計算するような音楽表現には一定の限界があることを指摘している[@Puckette2015]。たしかに、プログラミング言語を使うということは、シンボルを組み合わせることである（ときには実在しないかもしれない）現象のモデルを記述し、それをコンピューターに実行させているということなのだから、例えばバネ–マス–ダンパといったシンボルを組み合わせてある力学系のモデルをテキストとして記述することは、モデルが連続領域であろうと離散領域であろうと可能だし、連続領域のモデルとして記述されたシンボルの組み合わせを離散化する関数に通し、信号処理に利用する、といった方法の記述は1つのソースコードの中に収めることも可能なはずだ(実際、Wolframのような数値計算のための言語ではまさにそのような記述が可能である[^wolfram])。これもやはり、モデルを離散化するという計算が大抵はコンパイルしたタイミングで発生しており、いつ計算するかの意味論が存在しないことにより、連続領域のモデル記述は一度離散化したデータを読み込むといったプロセスを経なければ記述ができないという見方ができるだろう。この考え方をもう少し進めれば、例えば微分方程式のモデルを記述する、という作業を機械学習におけるモデル学習のための関数を記述する、という置き換えもできる。もちろん、現実的には機械学習のようなモデル学習に計算リソースを激しく使うようなケースでは、コードを実行するたびに学習し直しということになっては非効率極まりないので、計算した結果をキャッシュするような仕組みがコンパイラに必要になるだろうが。

言い方を変えると、Wavファイルによるサンプルやウェーブテーブルも、連続領域モデルを離散化した後の重みづけパラメーターのような計算結果も、機械学習における学習語のモデルデータも、**何かしらのモデルから生成されたキャッシュ**のようなものと捉えることもできるだろう。この、いつ計算するかを意味論に明示的に加えていくことは、現在の音楽情報処理において解離してしまっている、pythonを用いて学習、Maxなどのツールを用いてモデルを実行し音声をリアルタイムで出力といったような2つの作業を1つながりの作業としてつなぎ合わせるような役割を音楽プログラミング言語に与えることに繋がる。

[^wolfram]: https://reference.wolfram.com/language/howto/SolveADifferentialEquation.html.ja 2022年1月31日最終閲覧。

---

<!-- 4章のもの -->

このことから考えられるべき示唆はいくつもあるだろう。まず、今日使われているコンピューター技術は、クロード・シャノンの定理が音声の符号化に貢献したことに限らず、音や通信にまつわるテクノロジーの上に成り立っていることはより強調されて然るべきである。加えて、音響遅延線メモリーの生い立ちは、計算機技術の歴史的位置付けをCivil Engineering、つまり非軍事技術観点からさらに見直す材料にもなる。電子計算機が歴史的に軍事技術として現れてきたことはもはや否定のしようもないし、テクノロジーが常に非中立的にならざるを得ないことを工学者は頭に入れ続けなければならない。しかし同時に、計算機を戦争だけが生み出した怪物のように捉えてしまうことは、テクノロジーを責任を持って扱う今日のCivil Engieeringのあり方に何ら希望を与えてくれないという困難さも併せ持つ。ならば立てるべき問いとはこうなる。WW2無くして現代の電子計算機は生まれなかったのかもしれないが、同時にエッカートの、自らの楽しみや、身の回りの人の楽しみのために行ってきたティンカリング無くしても現代の電子計算機の姿はなかったのではないか？



メディア研究者の飯田豊はこの時期、ケージとも直接的に交流のあったマーシャル・マクルーハンの思想が広く流布され、かつこの時期の電子機器の低価格化により電気や通信機器（テレビやラジオ）というメディアが芸術家の素材になり始めたタイミングと重なったことが万博で行われた芸術家たちの実験につながっていることを指摘している。

> マクルーハンの芸術論における中心的な概念は、言うまでもなく「環境」である。マクルーハンによれば、メディアが環境化することによって、ある時代の現実が形成されるようになると、その影響は不可視なものになる。新しい環境が登場することで相対的に古くなり、目に見えるようになった前の時代の環境（＝「反環境」）を作品として意識化させるのが、芸術の役割に他ならない。そして，エレクトロニクスという新しいテクノロジーの環境が登場してきた現在、環境そのものが芸術として扱われる段階（＝「環境芸術」）に初めて達したのではないかと指摘する。

---

よりテクニカルな問題としてC++を基盤としない言語を用いて開発し直すという選択肢も考えられる。具体的には、C++（17）を用いての実装において、実装の参考にしたOCamlと比べると代数データ型の扱いが複雑になることが大きな障害となった。C++17においては、標準ライブラリに`std::variant`という、代数データ型における直和型（N種類の型のうちどれか1種類が含まれているような状態を示す型）が利用できるようになったが、これはAbstract Syntax Treeを表現するための木構造に用いる再帰する代数データ型(新しく型を定義するときに自分自身の項が含まれるような型）の定義を少し遠回りな方法でなければ実現できないことによる[^recursivevariant]。加えて、N個のvariantの中から各データ型に対応する処理を記述する際、OCaml等の関数型言語においてはパターンマッチと呼ばれる記法を用いて短く処理を記述することができる。C++でvariantを使った場合、テンプレートによる静的ポリモーフィズムの複雑な記述を行う必要がありこれも開発の効率を落とす一つの要因であった。そもそもC++を開発言語として選択したのは、第5章で説明した通り音楽のための言語を実装するにあたって、メモリの確保を明示的に制御できるような言語である必要性があることを意識していたという理由があるが、これは今にして思えばランタイムの実装（C++で書かれたプログラムならコンパイルされそのプログラムは静的にメモリを確保して動く）とコンパイラの実装(何かしらの言語で書かれたプログラムがLLVMライブラリなどを通じて静的にメモリを確保するようなプログラムを動的に出力する)を混同していたため、コンパイラ部分だけの実装を別の言語で実装することは可能である。ただ、幅広いプラットフォームをサポートしようと思えばLLVMが利用できることは重要な要素であるため、公式でそれらがサポートされているOCamlや、C言語APIをラップしたライブラリが存在しているHaskellやRustのような言語が異なる実装のための候補として挙げられる。

[^recursivevariant]: `std::variant`の実装の元となったboostライブラリの中には再帰するvariantが記述可能なものもある。URLなどで補足する

---

第2章前半で論じたように、プログラミング言語を設計する研究はその評価の基準の曖昧さの一方で、各技術要素については定量/定質様々な方法で客観性を持った評価をすることは可能だというHCIにおけるインターフェースデザインの主要な研究とはやや趣が異なる研究である。mimiumの設計も、第6章で論じてきた中心的な機能以外の部分に関しては実用性を考えた別個の機能が飛び飛びに開発されている。例えば本論の中では触れなかった、外部のファイルを読み込むincludeの機能などは音楽的に関わる意味論の設計の外側であったため、単純な文字列置き換えによる場当たり的実装となっている。一方でこの機能は開発されてなければ様々なコードのテストのファイルはライブラリのような機能分割をしない全て自己完結したコードでなければならない。

このような状態で、本論文の主要な主張(Claim)たる、音楽において自分のソフトウェアを自分で開発できるようなインフラストラクチャの形成という目標に対して、それを支える根拠（Evidence）は長期的目線での音楽情報インフラストラクチャの形成の必要性とそれに応じたなるべくブラックボックスを少なくするような言語の設計と実装という、いわば設計思想のみであって、個々の技術的要素、例えば、信号処理をLLVMを用いることでコードをメモリ上でコンパイルでき、リアルタイムで高速な処理が行える、といった要素は、例え厳密なベンチマークを行っていたとしても主張を支える十分な根拠とは現状なり得ない。mimiumという人工物に対するAnnotationとしてのこの主張と根拠の結びつきは、今後言語が少しづつ実用される中で初めて評価されることになる。

---

一方であえて重視しなかった機能として、近年の高レイヤーの拡張を試みる言語が同時に行ってきたコードの動的変更、つまりライブコーディングのための工夫はほとんどされていない。とはいえ、全体のアーキテクチャの参考としたExtemporeは低レイヤーの表現の自由度を担保しながらライブコーディングができることを目指した言語であり、LLVMという低レイヤーの処理をメモリ上でコンパイルして即時動作させるインフラストラクチャを用いているという共通点を見れば、少し手を加えることで、動的にコードを変更していった時に音声がブツ切れにならないかといった細かい考慮を度外視すれば実現自体は可能だと考えられる。ただし、その機能はLLVMのJITコンパイルのためのライブラリに依存することになるため、LLVMを使わないバックエンド–具体的には、Webブラウザ向けのWebassemblyバックエンドなどを追加しようと思った時の移植性が低くなってしまうことが予想できる。現在はコードの動的変更のしやすさよりも稼働できるプラットフォームの幅の広さの方に重きを置くべきと考えている。

---

mimiumは独自に新しく統語論の定義を行っているため、（その表面上の見た目である統語論はRustという既存のポピュラーな言語に寄せてあるものの）Internal DSLとして実装されている言語と比べてるとその学習コストは高いし、ホスト言語の既存のライブラリ資源の活用も難しい。つまり、既存の音楽プログラミング言語の利用者からの参入障壁が大きい。これはインフラストラクチャとしての言語という側面から考えると重要な問題で、給水塔という既存のインフラストラクチャに乗ることで広がる携帯電話の基地局という新しいインフラストラクチャ[@Parks2015,p2]のように、新しいインフラストラクチャを整備するために既存のインフラストラクチャを利用することは必須とは言わずとも、利用しないことによってハードルが格段に上がってしまう。設計当初、言語自体の表現力が高くできてさえいればあまり問題にならないだろうと考えていたが現在はその考えは間違えだったと感じている。すでに繰り返し述べているように音楽プログラミング言語の実装には時間がかかる。言語自体の実装やアップデートもそうだし、言語上で構築するライブラリはなおのことである。なぜなら、言語上で開発されたライブラリは言語の中核的な機能や、includeのようなモジュール読み込みのための機能が更新されたり変更されるのに伴って大きく変更される必要がままあるため、本腰を入れて開発を始めることが難しいからである。そうしたときに、外部の言語のライブラリを活用できるということは、言語の開発段階から実用性を失わずにコアな機能を少しずつ増やしていくことができることになる。

今後このような言語間の相互運用性を高めるための方法としては2つの方針が考えられる。1つは、別の言語の関数呼び出しの中で最も実装が簡単なC言語ライブラリの関数呼び出しを、mimium上でライブラリ名、関数名、型名を書けば実行時にリンクして呼び出せるようにする、いわゆるForeign Function Interface(FFI)の機能を追加することだ。ただ、簡単とはいえ、mimiumでは意味論上隠蔽されているハードウェア的な要素が含まれる型の扱い、つまりポインタ型の扱いを型システムの統語論にも追加しなければならないため、簡単とはいえコンパイラに入れる手間は比較的複雑なものとなる。

2つ目は、mimium自体をFaustのように、MaxやSuperColliderのUGenとして扱えるようなワークフローを整備することで他の言語の拡張機能的に使えるようにするという方法だ。Faustに限らずとも例えば現在は文字列から独自の構文解析を行う、典型的なExternal DSLであるSuperColliderもその元となった環境はPyriteというMaxのためのエクスターナルオブジェクトとして利用できるスクリプト言語だった[@McCartney2020]。これは既に、mimium自体のアーキテクチャをなるべく疎結合にしていたこともあり、アーキテクチャの図におけるオーディオドライバの部分に当たる箇所を、MaxやSuperColliderそれぞれのUGen作成のためのAPIを用いて実装すればよいため、C言語FFIの実装と比べると比較的簡単ではある。


---

PLfMのための最低限の抽象計算モデルの不在を理解した上で、それでも可能な限り最低限を目指したのがmimiumの設計方針である。この最低限の抽象化の不在はPLfMの研究として大きな課題であるのは間違いない。しかし、なるべく汎用性の高い言語が仮に作れたとして、それだけで、MIDIやUGenのような埋め込まれた音楽様式と異なる音楽が作られるようなことがあるのだろうか。もっと言えば、1950、1960年代のように、コンピューターを使って音楽を作ることが、コンピューターを理解してプログラムを作るという不可分な行為であったように、音楽家が主体的にコンピューターを扱えるような環境は、汎用性の高い、ブラックボックスのなるべく少ないPLfMを作るだけで実現可能なのだろうか？その、汎用性の高いPLfM自体はいったい誰が作るのだろうか？これが、mimiumを作るなかで最も強く感じた疑問と矛盾だった。

この矛盾の説明をするため、第5章で整理した、音楽プログラミング言語の実装の方針と、それに伴う特性のトレードオフがmimiumではどうなっていたかを改めて考える。

mimiumの実装方針は、中間表現の粒度を限りなく小さくするために、文字列データの解析から行うExternal DSLとなっていた。コンパイラ・コンパイラであるbisonを用いることで文字列解析の実装そのものはSuperColliderやFaust同様に下げられているが、C++という低レベルプログラミング言語での実装を行っているためその実装の手間（開発コスト）は少なくない。コードの動的変更の難しさや、開発コストの増大はあらかじめ想定されていた通りである。

しかしこの実装のコストは当初予想していたよりもずっと大きく、正弦波を鳴らすための音が出るまでに1年以上の時間を費やすという状況を引き起こし、開発の経験の大半は音に関連したトピックというよりもむしろ汎用プログラミング言語の開発とほとんど変わらないものになっていた。

これは実際mimiumという言語に特有の問題というわけではなく、Generalityを高めようとすれば必然的に発生する問題へと一般化できる。

---

- **イノベーションではなく、使用中(Not an Innovation but in use)**
- **応用ではなく、基盤と周縁（Not an Application but an Infrastructure and Merginal Area）**
- **誤用ではなく、開き直り（Not an Misuse but Being Defiant）**

こうした汎用性の高い言語そのものの実装の困難さを解消するための方法として、言語同士の相互運用性が上がればよいという立場をとることもできる。つまり、mimium自体をFaustのように、MaxやSuperColliderのUGenとして扱えるようなワークフローを整備することで他の言語の拡張機能的に使えるようにするという方法だ。Faustに限らずとも、例えば現在は文字列から独自の構文解析を行う典型的なExternal DSLである、SuperColliderもその元となった環境はPyriteというMax上で利用できるスクリプト言語だった。こうした埋め込みによる相互運用は既に、mimium自体のアーキテクチャをなるべく疎結合にしていたこともあり、アーキテクチャの図におけるオーディオドライバの部分に当たる箇所を、MaxやSuperColliderそれぞれのUGen作成のためのAPIを用いて実装すればよいため、比較的簡単ではある。


電子計算機が歴史的に軍事技術として現れてきたことはもはや否定のしようもないし、テクノロジーが常に非中立的にならざるを得ないことを工学者は頭に入れ続けなければならない。音楽のためを標榜したIRCAM 4Xが最終的に軍事目的に利用される結末に至ったことからもそれは明らかである。

しかし同時に、計算機を戦争だけが生み出した怪物のように捉えてしまうことは、テクノロジーを責任を持って扱う今日のCivil Engieeringのあり方に何ら希望を与えてくれないという困難さも併せ持つ。ならば立てるべき問いとはこうなる。WW2無くして現代の電子計算機は生まれなかったのかもしれないが、同時にエッカートの、自らの楽しみや、身の回りの人の楽しみのために行ってきたティンカリング無くしても現代の電子計算機の姿はなかったのではないか？

---


アマチュアリズム的態度に準じたハッキング/ティンカリング的態度に基づくテクノロジーの誤用はもはや、アクセス不可能なブラックボックスにより無効化され、コンピューターという象徴機械を介して音楽文化は無意識に画一的な方向に収束する傾向にある。

そうした時代に音楽家が取れる態度はまず、テクノロジーの中身そのものを根本的に理解できるようになっていくよう変わる必要があるし、音楽文化全体においてテクノロジーの理解を促すような教育も必要である。パケットはMaxやPureDataが比較的普及した後でも、それを使うためには教育の要素が不可欠だと主張しているが、この状況は現在になっても変わっていないと言える。

> しかし、コンピュータハードウェアの低廉化によって交わされた約束に、私たちはまだ追いついていない。確かに、いまやすべての道具が入ったコンピュータを400ドル程度で購入でき、アンプとスピーカを追加すればコンピュータ音楽制作の準備が整う。しかしこれは、システムを構築し、フリーの良いソフト見つけてインストールし実行するために必要な知識があることを前提としている。コンピュータを数千ドルに、ソフトウェアを数千ドルにしたいという多くの商業的な関心が、私たちの前に立ちはだかる。
> コンピューティングとコンピュータ音楽の民主化に不可欠な要素は、地域の知識ベースを育成することだ。将来を見据えた音楽教育者は、学生が自分のコンピュータを構築するのを促すために何時間も割いている。自家製コンピュータと自家製コンピュータ音楽ソフトウェアの国際的な文化を、いつか見たいと私は思う。過去に裕福な西側はソフトウェアを開発し、何百万ものCDを作り、買う人には誰にでも販売した。将来的には、他の世界から輸入されたソフトウェアを研究し学習するセンターを見てみたい。
> 知識を育てるコミュニティが、特にLinuxのような非商用OSでは必要である。もしLinuxを使う友人がいなければ、動かすまでには障害があるだろう。しかし、世界の多くで少なくとも村の1人や2人に、コンピュータ音楽の専門知識（マシンの組み立て方法、OSのインストール方法、ソフトウェアの実行方法など）がある未来を想像できる。[@Puckette2002]